# -*- coding: utf-8 -*-
"""KNN_sample.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fOPJF9UxfmviP8o60MXa-fixkdHN-JlM

# **KNN Basic Algorithm**
"""

#import google drive libraries
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

#Authenticating with google
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

#download data file from google drive
downloaded = drive.CreateFile({'id':"1RScLymrAhcMUxhOpqA0DcsTbzNnHMsIF"})  
downloaded.GetContentFile('diabetes_data.csv')

#import pandas
import pandas as pd

#read in the data using pandas
df = pd.read_csv('diabetes_data.csv')

#check data has been read in properly
df.head()

#check number of rows and columns in dataset
df.shape

#create a dataframe with all training data except the target column
X = df.drop(columns=['diabetes'])

#check that the target variable has been removed
X.head()

#separate target values
y = df['diabetes'].values

#view target values
y[0:5]

from sklearn.model_selection import train_test_split

#split dataset into train and test data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1, stratify=y)

from sklearn.neighbors import KNeighborsClassifier

# Create KNN classifier
knn = KNeighborsClassifier(n_neighbors = 3)

# Fit the classifier to the data
knn.fit(X_train,y_train)

#show first 5 model predictions on the test data
knn.predict(X_test)[0:5]

#check accuracy of our model on the test data
knn.score(X_test, y_test)

"""# **Advanced Methods for parameter tuning**

---

**k-Fold Cross-Validation**
"""

from sklearn.model_selection import cross_val_score
import numpy as np

#create a new KNN model
knn_cv = KNeighborsClassifier(n_neighbors=3)

#train model with cv of 5 
cv_scores = cross_val_score(knn_cv, X, y, cv=5)

#print each cv score (accuracy) and average them
print(cv_scores)
print('cv_scores mean:{}'.format(np.mean(cv_scores)))

"""**Hypertuning model parameters using GridSearchCV**"""

from sklearn.model_selection import GridSearchCV

#create new a knn model
knn2 = KNeighborsClassifier()

#create a dictionary of all values we want to test for n_neighbors
param_grid = {'n_neighbors': np.arange(1, 25)}

#use gridsearch to test all values for n_neighbors
knn_gscv = GridSearchCV(knn2, param_grid, cv=5)

#fit model to data
knn_gscv.fit(X, y)

#check top performing n_neighbors value
knn_gscv.best_params_

#check mean score for the top performing value of n_neighbors
knn_gscv.best_score_